{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этот ноутбук необходим для оценки показателей модели, обученной на Kaggle, так как Kaggle сломался и время на эксплуатацию GPU кончилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clean-fid in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (0.1.35)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (2.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.14.3 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (1.16.3)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (4.67.1)\n",
      "Requirement already satisfied: pillow>=8.1 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (12.0.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from clean-fid) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from tqdm>=4.28.1->clean-fid) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from requests->clean-fid) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from requests->clean-fid) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from requests->clean-fid) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from requests->clean-fid) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (2025.12.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from torch->clean-fid) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->clean-fid) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->clean-fid) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from jinja2->torch->clean-fid) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\mephi-env-311\\lib\\site-packages (from sympy->torch->clean-fid) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install clean-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=128, channels_img=3, features_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g*16, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(features_g*16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Добавляем residual blocks для лучшего качества\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            ResidualBlock(features_g*16),\n",
    "            ResidualBlock(features_g*16),\n",
    "        )\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # 4x4 -> 8x8\n",
    "            nn.ConvTranspose2d(features_g*16, features_g*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g*8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 8x8 -> 16x16\n",
    "            nn.ConvTranspose2d(features_g*8, features_g*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Self-Attention layer для глобальной согласованности\n",
    "            SelfAttention(features_g*4),\n",
    "            \n",
    "            # 16x16 -> 32x32\n",
    "            nn.ConvTranspose2d(features_g*4, features_g*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 32x32 -> 64x64\n",
    "            nn.ConvTranspose2d(features_g*2, channels_img, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z = z.view(-1, self.z_dim, 1, 1)\n",
    "        x = self.initial(z)\n",
    "        x = self.res_blocks(x)\n",
    "        return self.main(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, channels_img=3, features_d=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 64x64 -> 32x32\n",
    "            nn.Conv2d(channels_img, features_d, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 32x32 -> 16x16\n",
    "            nn.Conv2d(features_d, features_d*2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(features_d*2),  # Заменяем BatchNorm на InstanceNorm\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 16x16 -> 8x8\n",
    "            nn.Conv2d(features_d*2, features_d*4, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(features_d*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Self-Attention layer\n",
    "            SelfAttention(features_d*4),\n",
    "            \n",
    "            # 8x8 -> 4x4\n",
    "            nn.Conv2d(features_d*4, features_d*8, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(features_d*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 4x4 -> 1x1\n",
    "            nn.Conv2d(features_d*8, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Дополнительные модули\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_dim, in_dim//8, 1)\n",
    "        self.key = nn.Conv2d(in_dim, in_dim//8, 1)\n",
    "        self.value = nn.Conv2d(in_dim, in_dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, C, width, height = x.size()\n",
    "        query = self.query(x).view(batch, -1, width*height).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch, -1, width*height)\n",
    "        energy = torch.bmm(query, key)\n",
    "        attention = self.softmax(energy)\n",
    "        value = self.value(x).view(batch, -1, width*height)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch, C, width, height)\n",
    "        return self.gamma * out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация моделей\n",
    "generator = Generator().to(device)\n",
    "critic = Critic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 63565 изображений\n",
      "DataLoader создан. Размер батча: 64\n",
      "Количество батчей: 994\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Определим преобразования для изображений\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Изменяем размер до 64x64\n",
    "    transforms.ToTensor(),  # Преобразуем в тензор\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Нормализуем в диапазон [-1, 1]\n",
    "])\n",
    "\n",
    "# Создаем кастомный датасет\n",
    "class AnimeFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Директория с изображениями.\n",
    "            transform (callable, optional): Трансформации для изображений.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        \n",
    "        # Рекурсивно собираем все изображения\n",
    "        for filename in os.listdir(root_dir):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                self.image_paths.append(os.path.join(root_dir, filename))\n",
    "        \n",
    "        print(f\"Найдено {len(self.image_paths)} изображений\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Возвращаем изображение и метку (для совместимости, но метки не используются)\n",
    "        return image, 0\n",
    "\n",
    "# Создаем датасет\n",
    "dataset_path = './data_from_learn/input/images'  # Путь к вашим изображениям\n",
    "anime_dataset = AnimeFaceDataset(root_dir=dataset_path, transform=transform)\n",
    "\n",
    "# Создаем DataLoader\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(\n",
    "    anime_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Количество процессов для загрузки данных\n",
    "    # pin_memory=True  # Ускоряет передачу данных на GPU\n",
    ")\n",
    "\n",
    "print(f\"DataLoader создан. Размер батча: {batch_size}\")\n",
    "print(f\"Количество батчей: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from cleanfid import fid\n",
    "\n",
    "def get_images_to_fid_format(images_list):\n",
    "    \"\"\"\n",
    "    Преобразование картинок для clean-fid формата\n",
    "    \"\"\"\n",
    "    all_images = torch.cat(images_list, dim=0)\n",
    "    all_images = all_images * 0.5 + 0.5\n",
    "    all_images = all_images.mul(255).add(0.5).clamp(0, 255).permute(0, 2, 3, 1).to('cpu', torch.uint8).numpy()\n",
    "    return all_images\n",
    "\n",
    "def save_images_to_folder(image_array, folder_path, max_to_save=None):\n",
    "    \"\"\"\n",
    "    Сохранение изображений\n",
    "    \"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    num_images = image_array.shape[0]\n",
    "    if max_to_save is not None and max_to_save < num_images:\n",
    "        images_to_process = image_array[:max_to_save]\n",
    "        print(f\"Сохраняем первые {max_to_save} изображений в {folder_path}...\")\n",
    "    else:\n",
    "        images_to_process = image_array\n",
    "        print(f\"Сохраняем все {num_images} изображений в {folder_path}...\")\n",
    "\n",
    "    for i in tqdm(range(images_to_process.shape[0]), desc=f\"Сохранение в {os.path.basename(folder_path)}\"):\n",
    "        img = Image.fromarray(images_to_process[i])\n",
    "        img.save(os.path.join(folder_path, f\"{i:05d}.png\"))\n",
    "\n",
    "def calculate_final_fid_fixed(\n",
    "    trained_gen,\n",
    "    dataloader,\n",
    "    z_dim,\n",
    "    device,\n",
    "    num_samples=10000,\n",
    "    save_generated_path=None,\n",
    "    save_real_path=None,\n",
    "    max_saved_images=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Собирает реальные и фейковые изображения, преобразует их,\n",
    "    сохраняет во временные папки для FID и опционально сохраняет\n",
    "    изображения в постоянные папки.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Сбор реальных изображений\n",
    "    print(\"Собираем реальные изображения...\")\n",
    "    real_images_list = []\n",
    "    for images, _ in dataloader:\n",
    "        real_images_list.append(images.cpu())\n",
    "        if len(real_images_list) * dataloader.batch_size >= num_samples:\n",
    "            break\n",
    "    real_images_array = get_images_to_fid_format(real_images_list)[:num_samples]\n",
    "\n",
    "    if save_real_path:\n",
    "        print(f\"\\nОбнаружен save_real_path. Сохраняем реальные изображения в: {save_real_path}\")\n",
    "        # Сохраняем только часть, определенную max_saved_images\n",
    "        save_images_to_folder(real_images_array, save_real_path, max_to_save=max_saved_images)\n",
    "        print(\"Сохранение реальных изображений завершено.\")\n",
    "\n",
    "    # 2. Генерация фейковых изображений\n",
    "    print(f\"\\nГенерируем {num_samples} фейковых изображений...\")\n",
    "    trained_gen.eval()\n",
    "    fake_images_list = []\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    for i in tqdm(range(0, num_samples, batch_size), desc=\"Генерация изображений\"):\n",
    "        current_batch_size = min(batch_size, num_samples - i)\n",
    "        noise = torch.randn(current_batch_size, z_dim, 1, 1, device=device)\n",
    "        with torch.no_grad():\n",
    "            fake_batch = trained_gen(noise).cpu()\n",
    "        fake_images_list.append(fake_batch)\n",
    "\n",
    "    fake_images_array = get_images_to_fid_format(fake_images_list)\n",
    "\n",
    "    if save_generated_path:\n",
    "        print(f\"\\nОбнаружен save_generated_path. Сохраняем сгенерированные изображения в: {save_generated_path}\")\n",
    "        # Сохраняем только часть, определенную max_saved_images\n",
    "        save_images_to_folder(fake_images_array, save_generated_path, max_to_save=max_saved_images)\n",
    "        print(\"Сохранение сгенерированных изображений завершено.\")\n",
    "\n",
    "    # 3. Расчет FID: ИСПОЛЬЗУЕМ ВРЕМЕННЫЕ ПАПКИ\n",
    "    print(\"\\nНачинаем расчет FID...\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as real_dir, tempfile.TemporaryDirectory() as fake_dir:\n",
    "\n",
    "        # Для FID сохраняем все необходимые num_samples изображений\n",
    "        print(\"Сохраняем реальные изображения во временную папку для FID...\")\n",
    "        save_images_to_folder(real_images_array, real_dir, max_to_save=None)\n",
    "\n",
    "        print(\"Сохраняем фейковые изображения во временную папку для FID...\")\n",
    "        save_images_to_folder(fake_images_array, fake_dir, max_to_save=None)\n",
    "\n",
    "        fid_value = fid.compute_fid(\n",
    "            real_dir,\n",
    "            fake_dir,\n",
    "            model_name=\"inception_v3\",\n",
    "            device=device,\n",
    "            verbose=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial): Sequential(\n",
       "    (0): ConvTranspose2d(128, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (res_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): SelfAttention(\n",
       "      (query): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (key): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (value): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (7): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (11): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./data_from_learn/weights/netG_epoch_020.pth', map_location=device)\n",
    "generator.load_state_dict(state_dict)\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собираем реальные изображения...\n",
      "\n",
      "Обнаружен save_real_path. Сохраняем реальные изображения в: real_samples\n",
      "Сохраняем первые 100 изображений в real_samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение в real_samples: 100%|██████████| 100/100 [00:00<00:00, 1263.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение реальных изображений завершено.\n",
      "\n",
      "Генерируем 10000 фейковых изображений...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация изображений: 100%|██████████| 157/157 [01:27<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обнаружен save_generated_path. Сохраняем сгенерированные изображения в: generated_samples\n",
      "Сохраняем первые 100 изображений в generated_samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение в generated_samples: 100%|██████████| 100/100 [00:00<00:00, 961.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение сгенерированных изображений завершено.\n",
      "\n",
      "Начинаем расчет FID...\n",
      "Сохраняем реальные изображения во временную папку для FID...\n",
      "Сохраняем все 10000 изображений в C:\\Users\\Boris\\AppData\\Local\\Temp\\tmp5920kqb9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение в tmp5920kqb9: 100%|██████████| 10000/10000 [00:06<00:00, 1489.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняем фейковые изображения во временную папку для FID...\n",
      "Сохраняем все 10000 изображений в C:\\Users\\Boris\\AppData\\Local\\Temp\\tmp__auefw6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение в tmp__auefw6: 100%|██████████| 10000/10000 [00:06<00:00, 1475.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute FID between two folders\n",
      "Found 20000 images in the folder C:\\Users\\Boris\\AppData\\Local\\Temp\\tmp5920kqb9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID tmp5920kqb9 : 100%|██████████| 625/625 [15:37<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images in the folder C:\\Users\\Boris\\AppData\\Local\\Temp\\tmp__auefw6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID tmp__auefw6 : 100%|██████████| 625/625 [15:35<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Финальный FID score: 71.12\n"
     ]
    }
   ],
   "source": [
    "# Вычисление FID\n",
    "final_fid_score = calculate_final_fid_fixed(\n",
    "    trained_gen=generator,\n",
    "    dataloader=dataloader,\n",
    "    z_dim=128,\n",
    "    device=device,\n",
    "    num_samples=10000,\n",
    "    save_generated_path=\"generated_samples\",\n",
    "    save_real_path=\"real_samples\",\n",
    "    max_saved_images=100\n",
    ")\n",
    "\n",
    "print(f\"\\nФинальный FID score: {final_fid_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mephi-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
